<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">



    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Learning from Explanations with Neural Execution Tree </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>

<style>
  body{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .btn-group{background-color: white}
  .btn {background-color: white}
  #main-nav {padding-top:10px; padding-bottom:10px;}
  .card {font-family: 'Exo'; box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);}
  .header {font: "Montserrat"; }
  .card-header { border: 4px solid #eee;
                font-family: "Exo";}


  .main-title {font-weight: 700;  color: #2294e0;}

  .myAccordion {

  box-shadow: 0px 2px 14px 0px rgba(0, 0, 0, 0.10);
    border-radius: 10px;
    margin-bottom: 18px;
    padding-left: 15px;
    padding-bottom: 10px;
    padding-right: 15px;
    padding-top: 10px;
    background-color: rgba(255, 255, 255, 1);
  }

  #abstractExample.collapse:not(.show) {
  display: block;
  /* height = lineheight * no of lines to display */
  height: 4.5em;
  overflow: hidden;
  }

  #abstractExample.collapsing {
  height: 4.5em;
  }


#absShow.collapsed:after {
  content: '+ Show More';
}

#absShow:not(.collapsed):after {
  content: '- Show Less';
}
</style>


<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="livestream.html">Live</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Vis</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="speakers.html">Speakers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">FAQ</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

<div class="card m-3" style="">
  <div class="card-header">
    <h3 class="card-title main-title text-center" style="">
      Learning from Explanations with Neural Execution Tree
    </h3>

    <h5 class="card-subtitle mb-2 text-muted text-center">
      
      Ziqi Wang*,
      
      Yujia Qin*,
      
      Wenxuan Zhou,
      
      Jun Yan,
      
      Qinyuan Ye,
      
      Leonardo Neves,
      
      Zhiyuan Liu,
      
      Xiang Ren
      
    </h5>

    <center class="p-3">
      <a class="card-link" data-toggle="collapse" role="button" href="#details">
        <button class="btn btn-outline-secondary">
          Abstract
        </button>
      </a>


      <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/384b941e7fb13502fee54b50ee3a59950f4beae9.pdf">
        <button class="btn btn-outline-secondary">
          Paper
        </button>
      </a>
      <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=rJlUt0EYwS">
        <button class="btn btn-outline-secondary">
          OpenReview
        </button>
      </a>
    <!-- <span><a href="" class="btn btn-secondary">OpenReview</a></span> -->

    <a href="https://www.dropbox.com/sh/zkp19yr44yr8idt/AABpjFN3r2COIOub33L7DtfLa?dl=0" target="_blank"  class="card-link">
      <button class="btn btn-outline-secondary">
        Code
      </button>
    </a>

    <a href="" target="_blank"  class="card-link">
      <button class="btn btn-outline-secondary">
        Slides
      </button>
    </a>
    </center>

  </div>
</div>

<div id="details" class="card m-3 collapse" style="font-family: 'Cuprum'; box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
  <div class="card-body">
    <p class="card-text">
      <div id="abstractExample">
        <span class="font-weight-bold">Abstract:</span>
        While deep neural networks have achieved impressive performance on a range of NLP tasks, these data-hungry models heavily rely on labeled data, which restricts their applications in scenarios where data annotation is expensive. Natural language (NL) explanations have been demonstrated very useful additional supervision, which can provide sufficient domain knowledge for generating more labeled data over new instances, while the annotation time only doubles. However, directly applying them for augmenting model learning encounters two challenges: (1) NL explanations are unstructured and inherently compositional, which asks for a modularized model to represent their semantics, (2) NL explanations often have large numbers of linguistic variants, resulting in low recall and limited generalization ability. In this paper, we propose a novel Neural Execution Tree (NExT) framework to augment training data for text classification using NL explanations. After transforming NL explanations into executable logical forms by semantic parsing, NExT generalizes different types of actions specified by the logical forms for labeling data instances, which substantially increases the coverage of each NL explanation. Experiments on two NLP tasks (relation extraction and sentiment analysis) demonstrate its superiority over baseline methods. Its extension to multi-hop question answering achieves performance gain with light annotation effort.
      </div>

    </p>

    <p></p>
    <p class="card-text"><span class="font-weight-bold">Keywords:</span>
      
    </p>
  </div>
</div>

<div>
</div>

</div>


<!-- SlidesLive -->
<div id="presentation-embed-38915748" class="container container-sm"></div>
<script src='https://slideslive.com/embed_presentation.js'></script>
<script>
  embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        allowHiddenControlsWhenPaused: true,
        zoomRatio: 0.4,
        hideTitle: true
    });
</script>


<!-- Buttons -->
<div class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Paper Discussion       </h2>
    <!-- <span><a class="btn btn-secondary" href="https://gitter.im/iclr/posterrJlUt0EYwS/">Chat</a></span> -->
  </center>
  <p></p>

  <!-- Gitter -->
  <!-- <div id='discourse-comments'></div> -->


<!-- <script type="text/javascript"> -->
<!--   DiscourseEmbed = { discourseUrl: 'https://iclr.trydiscourse.com/', -->
<!--                      topicId: 20}; -->

<!--   (function() { -->
<!--     var d = document.createElement('script'); d.type = 'text/javascript'; d.async = true; -->
<!--     d.src = DiscourseEmbed.discourseUrl + 'javascripts/embed.js'; -->
<!--     (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(d); -->
<!--   })(); -->
<!-- </script> -->


  <div id="gitter" class="gitter container" height="600px">
    <center>
      <div class="border">

        <center> <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_rJlUt0EYwS?layout=embedded" width="900px" height="400px"></iframe> </center>
      </div>
    </center>
  </div>
</div>


  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
    <div class="card-deck">

      

  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_BkxRRkSKwr.html" class="text-dark"><h5 class="card-title">Towards Hierarchical Importance Attribution: Explaining Compositional Semantics for Neural Sequence Models</h5></a>

    </div>
      <div class="card-body">
        <p class="card-text"> We propose measurement of phrase importance and algorithms for hierarchical explanation of neural sequence model predictions</p>
      </div>

      <div class="card-footer">
      <center>
        <a href="poster_BkxRRkSKwr.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  

  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_HJgJtT4tvB.html" class="text-dark"><h5 class="card-title">ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning</h5></a>

    </div>
      <div class="card-body">
        <p class="card-text"> We introduce ReClor, a reading comprehension dataset requiring logical reasoning, and find that current state-of-the-art models struggle with real logical reasoning with poor performance near that of random guess.</p>
      </div>

      <div class="card-footer">
      <center>
        <a href="poster_HJgJtT4tvB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  

  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_Byg1v1HKDB.html" class="text-dark"><h5 class="card-title">Abductive Commonsense Reasoning</h5></a>

    </div>
      <div class="card-body">
        <p class="card-text"> Abductive reasoning is inference to the most plausible explanation. For example, if Jenny finds her house in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief broke into her house and  caus...</p>
      </div>

      <div class="card-footer">
      <center>
        <a href="poster_Byg1v1HKDB.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  

  <!-- <div class="col-sm-4" style="padding-bottom: 10px"> -->
  <div class="card" >
    <div class="card-header">
        <a href="poster_r1eIiCNYwS.html" class="text-dark"><h5 class="card-title">Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention</h5></a>

    </div>
      <div class="card-body">
        <p class="card-text"> We present Transformer-XH, which upgrades Transformer with eXtra Hop attentions to intrinsically model structured texts in a data driven way. </p>
      </div>

      <div class="card-footer">
      <center>
        <a href="poster_r1eIiCNYwS.html" class="btn btn-primary">Visit</a>
        </center>

      </div>
      <!-- </div> -->

  </div>
  
    </DIV>
          </DIV>
      </DIV>

</body>