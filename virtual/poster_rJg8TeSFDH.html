<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: An Exponential Learning Rate Schedule for Deep Learning </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Browse</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="events.html">Events</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Extras</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="about.html">About</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="card m-3" style="">
   <div class="card-header">
     <h3 class="card-title main-title text-center" style="">
       An Exponential Learning Rate Schedule for Deep Learning
     </h3>

     <h5 class="card-subtitle mb-2 text-muted text-center">
       
       Zhiyuan Li,
       
       Sanjeev Arora
       
     </h5>

     <center class="p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
         <button class="btn btn-outline-secondary">
           Abstract
         </button>
       </a>


       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/c0a5feba02a5a8332a346bf69eb4ec194a8c9a24.pdf">
         <button class="btn btn-outline-secondary">
           Paper
         </button>
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=rJg8TeSFDH">
         <button class="btn btn-outline-secondary">
           OpenReview
         </button>
       </a>

       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Zoom
         </button>
       </a>

       <a href="https://iclr.rocket.chat/channel/paper_channel_rJg8TeSFDH" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Chat
         </button>
       </a>

       

       
     </center>

   </div>
 </div>

 <div id="details" class="card m-3 collapse" style=" box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Intriguing empirical evidence exists that deep learning can work well with exotic schedules for varying the learning rate. This paper suggests that the phenomenon may be due to Batch Normalization or BN(Ioffe &amp; Szegedy, 2015), which is ubiq- uitous and provides benefits in optimization and generalization across all standard architectures. The following new results are shown about BN with weight decay and momentum (in other words, the typical use case which was not considered in earlier theoretical analyses of stand-alone BN (Ioffe &amp; Szegedy, 2015; Santurkar et al., 2018; Arora et al., 2018)
• Training can be done using SGD with momentum and an exponentially in- creasing learning rate schedule, i.e., learning rate increases by some (1 + α) factor in every epoch for some α &gt; 0. (Precise statement in the paper.) To the best of our knowledge this is the first time such a rate schedule has been successfully used, let alone for highly successful architectures. As ex- pected, such training rapidly blows up network weights, but the net stays well-behaved due to normalization.
• Mathematical explanation of the success of the above rate schedule: a rigor- ous proof that it is equivalent to the standard setting of BN + SGD + Standard Rate Tuning + Weight Decay + Momentum. This equivalence holds for other normalization layers as well, Group Normalization(Wu &amp; He, 2018), Layer Normalization(Ba et al., 2016), Instance Norm(Ulyanov et al., 2016), etc.
• A worked-out toy example illustrating the above linkage of hyper- parameters. Using either weight decay or BN alone reaches global minimum, but convergence fails when both are used.
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="keyword_batch normalization.html" class="text-secondary text-decoration-none">batch normalization</a>,
       
       <a href="keyword_weight decay.html" class="text-secondary text-decoration-none">weight decay</a>,
       
       <a href="keyword_learning rate.html" class="text-secondary text-decoration-none">learning rate</a>,
       
       <a href="keyword_deep learning theory.html" class="text-secondary text-decoration-none">deep learning theory</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="jumbotron" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_rJg8TeSFDH?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HJx8HANFDH.html" class="text-muted">
              <h5 class="card-title" align="center">Four Things Everyone Should Know to Improve Batch Normalization</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Cecilia Summers,
              
              Michael J. Dinneen,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HJx8HANFDH.png" width="80%"/></center>

            <!-- <p class="card-text"> Four things that improve batch normalization across all batch sizes</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_H1enKkrFDB.html" class="text-muted">
              <h5 class="card-title" align="center">Stable Rank Normalization for Improved Generalization in Neural Networks and GANs</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Amartya Sanyal,
              
              Philip H. Torr,
              
              Puneet K. Dokania,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/H1enKkrFDB.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose Stable Rank Normalisation, a new regularisor based on recent generelization bounds and show how to optimize it with extensive experiments.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_SkgGjRVKDS.html" class="text-muted">
              <h5 class="card-title" align="center">Towards Stabilizing Batch Statistics in Backward Propagation of Batch Normalization</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Junjie Yan,
              
              Ruosi Wan,
              
              Xiangyu Zhang,
              
              Wei Zhang,
              
              Yichen Wei,
              
              Jian Sun,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SkgGjRVKDS.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose a novel normalization method to handle small batch size cases.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HyxJhCEFDS.html" class="text-muted">
              <h5 class="card-title" align="center">Intriguing Properties of Adversarial Training at Scale</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Cihang Xie,
              
              Alan Yuille,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HyxJhCEFDS.png" width="80%"/></center>

            <!-- <p class="card-text"> The first rigor diagnose of large-scale adversarial training on ImageNet</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>