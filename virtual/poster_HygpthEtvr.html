<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: ProxSGD: Training Structured Neural Networks under Regularization and Constraints </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link"    href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" target="_blank"   href="https://iclr.6connex.com/event/VirtualEvent/">Sponsor Hall</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="about.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       ProxSGD: Training Structured Neural Networks under Regularization and Constraints
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Yang Yang,
       
       Yaxiong Yuan,
       
       Avraam Chatzimichailidis,
       
       Ruud JG van Sloun,
       
       Lei Lei,
       
       Symeon Chatzinotas
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/2e4a2c27aad4203712646c19389c185bbe43adc7.pdf">
           Paper
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=HygpthEtvr">
           OpenReview
       </a>

     <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Zoom
       </a>

       <a href="https://iclr.rocket.chat/channel/paper_channel_HygpthEtvr" target="_blank"  class="card-link">
           Chat
       </a>

       
       <a href="https://github.com/optyang/proxsgd; https://github.com/cc-hpc-itwm/proxsgd" target="_blank"  class="card-link">
           Code
       </a>
       

       
     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         In this paper, we consider the problem of training neural networks (NN). To promote a NN with specific structures, we explicitly take into consideration the nonsmooth regularization (such as L1-norm) and constraints (such as interval constraint). This is formulated as a constrained nonsmooth nonconvex optimization problem, and we propose a convergent proximal-type stochastic gradient descent (Prox-SGD) algorithm. We show that under properly selected learning rates, momentum eventually resembles the unknown real gradient and thus is crucial in analyzing the convergence. We establish that with probability 1, every limit point of the sequence generated by the proposed Prox-SGD is a stationary point. Then the Prox-SGD is tailored to train a sparse neural network and a binary neural network, and the theoretical analysis is also supported by extensive numerical tests.
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=stochastic gradient descent" class="text-secondary text-decoration-none">stochastic gradient descent</a>,
       
       <a href="papers.html?filter=keywords&search=regularization" class="text-secondary text-decoration-none">regularization</a>,
       
       <a href="papers.html?filter=keywords&search=constrained optimization" class="text-secondary text-decoration-none">constrained optimization</a>,
       
       <a href="papers.html?filter=keywords&search=nonsmooth optimization" class="text-secondary text-decoration-none">nonsmooth optimization</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_HygpthEtvr?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_rkeNfp4tPr.html" class="text-muted">
              <h5 class="card-title" align="center">Escaping Saddle Points Faster with Stochastic Momentum</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Jun-Kun Wang,
              
              Chi-Heng Lin,
              
              Jacob Abernethy,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rkeNfp4tPr.png" width="80%"/></center>

            <!-- <p class="card-text"> Higher momentum parameter $\beta$ helps for escaping saddle points faster</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_SJeLIgBKPS.html" class="text-muted">
              <h5 class="card-title" align="center">Gradient Descent Maximizes the Margin of Homogeneous Neural Networks</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Kaifeng Lyu,
              
              Jian Li,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SJeLIgBKPS.png" width="80%"/></center>

            <!-- <p class="card-text"> We study the implicit bias of gradient descent and prove under a minimal set of assumptions that the parameter direction of homogeneous models converges to KKT points of a natural margin maximization problem.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BJgnXpVYwS.html" class="text-muted">
              <h5 class="card-title" align="center">Why Gradient Clipping Accelerates Training: A Theoretical Justification for Adaptivity</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Jingzhao Zhang,
              
              Tianxing He,
              
              Suvrit Sra,
              
              Ali Jadbabaie,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BJgnXpVYwS.png" width="80%"/></center>

            <!-- <p class="card-text"> Gradient clipping provably accelerates gradient descent for non-smooth non-convex functions.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_B1lLw6EYwB.html" class="text-muted">
              <h5 class="card-title" align="center">Gap-Aware Mitigation of Gradient Staleness</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Saar Barkai,
              
              Ido Hakimi,
              
              Assaf Schuster,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/B1lLw6EYwB.png" width="80%"/></center>

            <!-- <p class="card-text"> A new distributed, asynchronous, SGD-based algorithm, which achieves state-of-the-art accuracy on existing architectures using staleness penalization without having to re-tune the hyperparameters.</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>