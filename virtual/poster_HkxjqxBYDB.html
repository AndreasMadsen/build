<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Episodic Reinforcement Learning with Associative Memory </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link"    href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" target="_blank"   href="https://iclr.6connex.com/event/VirtualEvent/">Sponsor Hall</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="about.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       Episodic Reinforcement Learning with Associative Memory
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Guangxiang Zhu*,
       
       Zichuan Lin*,
       
       Guangwen Yang,
       
       Chongjie Zhang
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/1512938bac7377947bfce4dab3d34b8330ea3ec7.pdf">
           Paper
       </a>
       
       
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=HkxjqxBYDB">
           Reviews
       </a>

       <!--  -->
       <!-- <a href="" target="_blank"  class="card-link"> -->
       <!--   Slides -->
       <!-- </a> -->
       <!--  -->

       <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Video
       </a>

       <a href="chat.html?room=channel/paper_channel_HkxjqxBYDB" target="_blank"  class="card-link">
           Chat
       </a>

       


     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Sample efficiency has been one of the major challenges for deep reinforcement learning. Non-parametric episodic control has been proposed to speed up parametric reinforcement learning by rapidly latching on previously successful policies. However, previous work on episodic reinforcement learning neglects the relationship between states and only stored the experiences as unrelated items. To improve sample efficiency of reinforcement learning, we propose a novel framework, called Episodic Reinforcement Learning with Associative Memory (ERLAM), which associates related experience trajectories to enable reasoning effective strategies. We build a graph on top of states in memory based on state transitions and develop a reverse-trajectory propagation strategy to allow rapid value propagation through the graph. We use the non-parametric associative memory as early guidance for a parametric reinforcement learning model. Results on navigation domain and Atari games show our framework achieves significantly higher sample efficiency than state-of-the-art episodic reinforcement learning models.
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=Deep Reinforcement Learning" class="text-secondary text-decoration-none">Deep Reinforcement Learning</a>,
       
       <a href="papers.html?filter=keywords&search=Episodic Control" class="text-secondary text-decoration-none">Episodic Control</a>,
       
       <a href="papers.html?filter=keywords&search=Episodic Memory" class="text-secondary text-decoration-none">Episodic Memory</a>,
       
       <a href="papers.html?filter=keywords&search=Associative Memory" class="text-secondary text-decoration-none">Associative Memory</a>,
       
       <a href="papers.html?filter=keywords&search=Non-Parametric Method" class="text-secondary text-decoration-none">Non-Parametric Method</a>,
       
       <a href="papers.html?filter=keywords&search=Sample Efficiency" class="text-secondary text-decoration-none">Sample Efficiency</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_HkxjqxBYDB?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BJeGlJStPr.html" class="text-muted">
              <h5 class="card-title" align="center">IMPACT: Importance Weighted Asynchronous Architectures with Clipped Target Networks</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Michael Luo,
              
              Jiahao Yao,
              
              Richard Liaw,
              
              Eric Liang,
              
              Ion Stoica,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BJeGlJStPr.png" width="80%"/></center>

            <!-- <p class="card-text"> IMPACT helps RL agents train faster by decreasing training wall-clock time and increasing sample efficiency simultaneously.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_Bkl7bREtDr.html" class="text-muted">
              <h5 class="card-title" align="center">AMRL: Aggregated Memory For Reinforcement Learning</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Jacob Beck,
              
              Kamil Ciosek,
              
              Sam Devlin,
              
              Sebastian Tschiatschek,
              
              Cheng Zhang,
              
              Katja Hofmann,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/Bkl7bREtDr.png" width="80%"/></center>

            <!-- <p class="card-text"> In Deep RL, order-invariant functions can be used in conjunction with standard memory modules to improve gradient decay and resilience to noise.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_Sye57xStvB.html" class="text-muted">
              <h5 class="card-title" align="center">Never Give Up: Learning Directed Exploration Strategies</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Adrià Puigdomènech Badia,
              
              Pablo Sprechmann,
              
              Alex Vitvitskyi,
              
              Daniel Guo,
              
              Bilal Piot,
              
              Steven Kapturowski,
              
              Olivier Tieleman,
              
              Martin Arjovsky,
              
              Alexander Pritzel,
              
              Andrew Bolt,
              
              Charles Blundell,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/Sye57xStvB.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose a reinforcement learning agent to solve hard exploration games by learning a range of directed exploratory policies. </p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BJgZGeHFPH.html" class="text-muted">
              <h5 class="card-title" align="center">Dynamics-Aware Embeddings</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              William Whitney,
              
              Rajat Agarwal,
              
              Kyunghyun Cho,
              
              Abhinav Gupta,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BJgZGeHFPH.png" width="80%"/></center>

            <!-- <p class="card-text"> State and action embeddings which incorporate the dynamics improve exploration and RL from pixels.</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>