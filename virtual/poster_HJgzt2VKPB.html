<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">



    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: CATER: A diagnostic dataset for Compositional Actions &amp; TEmporal Reasoning </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>

<style>
  body{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .jumbotron{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .btn-group{background-color: white}
  .btn {background-color: white}
  #main-nav {padding-top:10px; padding-bottom:10px;}
  .card {font-family: 'Exo'; box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);}
  .header {font: "Montserrat"; }
  .card-header { border: 4px solid #eee;
                font-family: "Exo";}

  
  .main-title {font-weight: 700;  color: #2294e0;}

  .myAccordion {

  box-shadow: 0px 2px 14px 0px rgba(0, 0, 0, 0.10);
    border-radius: 10px;
    margin-bottom: 18px;
    padding-left: 15px;
    padding-bottom: 10px;
    padding-right: 15px;
    padding-top: 10px;
    background-color: rgba(255, 255, 255, 1);
  }

  .sponsorLogo {
  width: 250px;
  display: block;
  margin-left: auto;
    margin-right: auto;
  margin-top: auto;
    margin-bottom: auto;

  }
  
  .slp {

  background: #fff

  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  .border {
  background: #fff
  
  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  #abstractExample.collapse:not(.show) {
  display: block;
  /* height = lineheight * no of lines to display */
  height: 4.5em;
  overflow: hidden;
  }

  #abstractExample.collapsing {
  height: 4.5em;
  }


#absShow.collapsed:after {
  content: '+ Show More';
}

#absShow:not(.collapsed):after {
  content: '- Show Less';
}
</style>


<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="livestream.html">Live</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Vis</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="speakers.html">Speakers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">FAQ</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="card m-3" style="">
   <div class="card-header">
     <h3 class="card-title main-title text-center" style="">
       CATER: A diagnostic dataset for Compositional Actions &amp; TEmporal Reasoning
     </h3>
     
     <h5 class="card-subtitle mb-2 text-muted text-center">
       
       Rohit Girdhar,
       
       Deva Ramanan
       
     </h5>
     
     <center class="p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
         <button class="btn btn-outline-secondary">
           Abstract
         </button>
       </a>
       

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/e7991931c9ae42f5da1f8359a26e59c14a195139.pdf">
         <button class="btn btn-outline-secondary">
           Paper
         </button>
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=HJgzt2VKPB">
         <button class="btn btn-outline-secondary">
           OpenReview
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Zoom
         </button>
       </a>
       
       <a href="http://rohitgirdhar.github.io/CATER" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Code
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Slides
         </button>
       </a>
     </center>
     
   </div>
 </div>

 <div id="details" class="card m-3 collapse" style=" box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Computer vision has undergone a dramatic revolution in performance, driven in large part through deep features trained on large-scale supervised datasets. However, much of these improvements have focused on static image analysis; video understanding has seen rather modest improvements. Even though new datasets and spatiotemporal models have been proposed, simple frame-by-frame classification methods often still remain competitive. We posit that current video datasets are plagued with implicit biases over scene and object structure that can dwarf variations in temporal structure. In this work, we build a video dataset with fully observable and controllable object and scene bias, and which truly requires spatiotemporal understanding in order to be solved. Our dataset, named CATER, is rendered synthetically using a library of standard 3D objects, and tests the ability to recognize compositions of object movements that require long-term reasoning. In addition to being a challenging dataset, CATER also provides a plethora of diagnostic tools to analyze modern spatiotemporal video architectures by being completely observable and controllable. Using CATER, we provide insights into some of the most recent state of the art deep video architectures.
       </div>
       
     </p>
     
     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="keyword_Video Understanding.html" class="text-secondary text-decoration-none">Video Understanding</a>,
       
       <a href="keyword_Temporal Reasoning.html" class="text-secondary text-decoration-none">Temporal Reasoning</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



<div class="container ">
  <div class="row m-2">
    <div class="col-7">
      <div id="presentation-embed-38915748" class="slp"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        allowHiddenControlsWhenPaused: true,
        zoomRatio: 0.4,
        hideTitle: true
        });
      </script>
    </div>
    
    <div class="col-5 p-1 my-auto">        
        <div id="gitter" class="gitter container " >
          <center>
            <div class="border">
              <center> <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_HJgzt2VKPB?layout=embedded" width="100%" height="680px"></iframe> </center>
            </div>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
  

      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_rJgsskrFwH.html" class="text-dark"><h5 class="card-title">Scaling Autoregressive Video Models</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/rJgsskrFwH.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> We present a novel autoregressive video generation that achieves strong results on popular datasets and produces encouraging continuations of real world videos.</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_SJgMK64Ywr.html" class="text-dark"><h5 class="card-title">AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/SJgMK64Ywr.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> We search for multi-stream neural architectures with better connectivity and spatio-temporal interactions for video understanding.</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_SJxrKgStDH.html" class="text-dark"><h5 class="card-title">SCALOR: Generative World Models with Scalable Object Representations</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/SJxrKgStDH.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Scalability in terms of object density in a scene is a primary challenge in unsupervised sequential object-oriented representation learning. Most of the previous models have been shown to work only on scenes with a few objects. In this paper, we prop...</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_SJeLopEYDH.html" class="text-dark"><h5 class="card-title">V4D: 4D Convolutional Neural Networks for Video-level Representation Learning</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/SJeLopEYDH.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> A novel 4D CNN structure for video-level representation learning, surpassing  recent 3D CNNs.</p>
            
          </div>      
        </div>
      </div>
      
  </DIV>
</DIV>

</body>