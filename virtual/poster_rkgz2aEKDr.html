<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: On the Variance of the Adaptive Learning Rate and Beyond </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link"    href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" target="_blank"   href="https://iclr.6connex.com/event/VirtualEvent/">Sponsor Hall</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="about.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       On the Variance of the Adaptive Learning Rate and Beyond
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Liyuan Liu,
       
       Haoming Jiang,
       
       Pengcheng He,
       
       Weizhu Chen,
       
       Xiaodong Liu,
       
       Jianfeng Gao,
       
       Jiawei Han
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/4dbb68ed4eb409f773d227c4c157de6b31b3080b.pdf">
           Paper
       </a>
       
       <a href="https://github.com/LiyuanLucasLiu/RAdam" target="_blank"  class="card-link">
           Code
       </a>
       
       
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=rkgz2aEKDr">
           Reviews
       </a>

       <!--  -->
       <!-- <a href="" target="_blank"  class="card-link"> -->
       <!--   Slides -->
       <!-- </a> -->
       <!--  -->

       <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Video
       </a>

       <a href="chat.html?room=channel/paper_channel_rkgz2aEKDr" target="_blank"  class="card-link">
           Chat
       </a>

       


     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         The learning rate warmup heuristic achieves remarkable success in stabilizing training, accelerating convergence and improving generalization for adaptive stochastic optimization algorithms like RMSprop and Adam. Pursuing the theory behind warmup, we identify a problem of the adaptive learning rate -- its variance is problematically large in the early stage, and presume warmup works as a variance reduction technique. We provide both empirical and theoretical evidence to verify our hypothesis. We further propose Rectified Adam (RAdam), a novel variant of Adam, by introducing a term to rectify the variance of the adaptive learning rate. Experimental results on image classification, language modeling, and neural machine translation verify our intuition and demonstrate the efficacy and robustness of RAdam. 
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=warmup" class="text-secondary text-decoration-none">warmup</a>,
       
       <a href="papers.html?filter=keywords&search=adam" class="text-secondary text-decoration-none">adam</a>,
       
       <a href="papers.html?filter=keywords&search=adaptive learning rate" class="text-secondary text-decoration-none">adaptive learning rate</a>,
       
       <a href="papers.html?filter=keywords&search=variance" class="text-secondary text-decoration-none">variance</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_rkgz2aEKDr?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_rkeNfp4tPr.html" class="text-muted">
              <h5 class="card-title" align="center">Escaping Saddle Points Faster with Stochastic Momentum</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Jun-Kun Wang,
              
              Chi-Heng Lin,
              
              Jacob Abernethy,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rkeNfp4tPr.png" width="80%"/></center>

            <!-- <p class="card-text"> Higher momentum parameter $\beta$ helps for escaping saddle points faster</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_Syx4wnEtvH.html" class="text-muted">
              <h5 class="card-title" align="center">Large Batch Optimization for Deep Learning: Training BERT in 76 minutes</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Yang You,
              
              Jing Li,
              
              Sashank Reddi,
              
              Jonathan Hseu,
              
              Sanjiv Kumar,
              
              Srinadh Bhojanapalli,
              
              Xiaodan Song,
              
              James Demmel,
              
              Kurt Keutzer,
              
              Cho-Jui Hsieh,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/Syx4wnEtvH.png" width="80%"/></center>

            <!-- <p class="card-text"> A fast optimizer for general applications and large-batch training.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_ryxz8CVYDH.html" class="text-muted">
              <h5 class="card-title" align="center">Learning to Learn by Zeroth-Order Oracle</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Yangjun Ruan,
              
              Yuanhao Xiong,
              
              Sashank Reddi,
              
              Sanjiv Kumar,
              
              Cho-Jui Hsieh,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/ryxz8CVYDH.png" width="80%"/></center>

            <!-- <p class="card-text"> Novel variant of learning to learn framework for zeroth-order optimization that learns both the update rule and the Gaussian sampling rule.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_r1g87C4KwB.html" class="text-muted">
              <h5 class="card-title" align="center">The Break-Even Point on Optimization Trajectories of Deep Neural Networks</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Stanislaw Jastrzebski,
              
              Maciej Szymczak,
              
              Stanislav Fort,
              
              Devansh Arpit,
              
              Jacek Tabor,
              
              Kyunghyun Cho*,
              
              Krzysztof Geras*,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/r1g87C4KwB.png" width="80%"/></center>

            <!-- <p class="card-text"> In the early phase of training of deep neural networks there exists a &#34;break-even point&#34; which determines properties of the entire optimization trajectory.</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>