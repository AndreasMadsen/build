<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Minimizing FLOPs to Learn Efficient Sparse Representations </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Browse</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="events.html">Events</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Booths</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Extras</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="about.html">About</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       Minimizing FLOPs to Learn Efficient Sparse Representations
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Biswajit Paria,
       
       Chih-Kuan Yeh,
       
       Ian E.H. Yen,
       
       Ning Xu,
       
       Pradeep Ravikumar,
       
       Barnabás Póczos
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/91215045fcdc274bcbe6cb882ecc9f9c95e39d5b.pdf">
           Paper
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=SygpC6Ntvr">
           OpenReview
       </a>

     <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Zoom
       </a>

       <a href="https://iclr.rocket.chat/channel/paper_channel_SygpC6Ntvr" target="_blank"  class="card-link">
           Chat
       </a>

       
       <a href="https://github.com/biswajitsc/sparse-embed" target="_blank"  class="card-link">
           Code
       </a>
       

       
     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Deep representation learning has become one of the most widely adopted approaches for visual search, recommendation, and identification. Retrieval of such  representations from a large database is however computationally challenging. Approximate methods based on learning compact representations, have been widely explored for this problem, such as locality sensitive hashing, product quantization, and PCA. In this work, in contrast to learning compact representations, we propose to learn high dimensional and sparse representations that have similar representational capacity as dense embeddings while being more efficient due to sparse matrix multiplication operations which can be much faster than dense multiplication. Following the key insight that the number of operations decreases quadratically with the sparsity of embeddings provided the non-zero entries are distributed uniformly across dimensions, we propose a novel approach to learn such distributed sparse embeddings via the use of a carefully constructed regularization function that directly minimizes a continuous relaxation of the number of floating-point operations (FLOPs) incurred during retrieval. Our experiments show that our approach is competitive to the other baselines and yields a similar or better speed-vs-accuracy tradeoff on practical datasets
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=sparse embeddings" class="text-secondary text-decoration-none">sparse embeddings</a>,
       
       <a href="papers.html?filter=keywords&search=deep representations" class="text-secondary text-decoration-none">deep representations</a>,
       
       <a href="papers.html?filter=keywords&search=metric learning" class="text-secondary text-decoration-none">metric learning</a>,
       
       <a href="papers.html?filter=keywords&search=regularization" class="text-secondary text-decoration-none">regularization</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_SygpC6Ntvr?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HkxARkrFwB.html" class="text-muted">
              <h5 class="card-title" align="center">word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Aliakbar Panahi,
              
              Seyran Saeedi,
              
              Tom Arodz,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HkxARkrFwB.png" width="80%"/></center>

            <!-- <p class="card-text"> We use ideas from quantum computing to propose word embeddings that utilize much fewer trainable parameters.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_BkxpMTEtPB.html" class="text-muted">
              <h5 class="card-title" align="center">GLAD: Learning Sparse Graph Recovery</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Harsh Shrivastava,
              
              Xinshi Chen,
              
              Binghong Chen,
              
              Guanghui Lan,
              
              Srinivas Aluru,
              
              Han Liu,
              
              Le Song,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/BkxpMTEtPB.png" width="80%"/></center>

            <!-- <p class="card-text"> A data-driven learning algorithm based on unrolling the Alternating Minimization optimization for sparse graph recovery.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HyeYTgrFPB.html" class="text-muted">
              <h5 class="card-title" align="center">Massively Multilingual Sparse Word Representations</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Gábor Berend,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HyeYTgrFPB.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose an efficient algorithm for determining multilingually comparable sparse word representations that we release for 27 typologically diverse languages.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_SJxzFySKwH.html" class="text-muted">
              <h5 class="card-title" align="center">On the Equivalence between Positional Node Embeddings and Structural Graph Representations</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Balasubramaniam Srinivasan,
              
              Bruno Ribeiro,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SJxzFySKwH.png" width="80%"/></center>

            <!-- <p class="card-text"> We develop the foundations of a unifying theoretical framework connecting node embeddings and structural graph representations through invariant theory</p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>