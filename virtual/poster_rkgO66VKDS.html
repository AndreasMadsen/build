<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">



    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: LEARNED STEP SIZE QUANTIZATION </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>

<style>
  body{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .jumbotron{font-family: 'Lato', sans-serif; background-color: rgba(236, 241, 246, 1)}
  .btn-group{background-color: white}
  .btn {background-color: white}
  #main-nav {padding-top:10px; padding-bottom:10px;}
  .card {font-family: 'Exo'; box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);}
  .header {font: "Montserrat"; }
  .card-header { border: 4px solid #eee;
                font-family: "Exo";}

  
  .main-title {font-weight: 700;  color: #2294e0;}

  .myAccordion {

  box-shadow: 0px 2px 14px 0px rgba(0, 0, 0, 0.10);
    border-radius: 10px;
    margin-bottom: 18px;
    padding-left: 15px;
    padding-bottom: 10px;
    padding-right: 15px;
    padding-top: 10px;
    background-color: rgba(255, 255, 255, 1);
  }

  .sponsorLogo {
  width: 250px;
  display: block;
  margin-left: auto;
    margin-right: auto;
  margin-top: auto;
    margin-bottom: auto;

  }
  
  .slp {

  background: #fff

  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  .border {
  background: #fff
  
  padding: 10px;

  border: 4px solid #eee;

  box-shadow: rgb(204, 204, 204) 2px 2px 14px 0px;
  }
  
  #abstractExample.collapse:not(.show) {
  display: block;
  /* height = lineheight * no of lines to display */
  height: 4.5em;
  overflow: hidden;
  }

  #abstractExample.collapsing {
  height: 4.5em;
  }


#absShow.collapsed:after {
  content: '+ Show More';
}

#absShow:not(.collapsed):after {
  content: '- Show Less';
}
</style>


<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="#">
      <img class="logo" style='visibility: ' src="static/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link" href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="livestream.html">Live</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="paper_vis.html">Vis</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="speakers.html">Speakers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="sponsors.html">Sponsors</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" href="faq.html">FAQ</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="card m-3" style="">
   <div class="card-header">
     <h3 class="card-title main-title text-center" style="">
       LEARNED STEP SIZE QUANTIZATION
     </h3>
     
     <h5 class="card-subtitle mb-2 text-muted text-center">
       
       Steven K. Esser,
       
       Jeffrey L. McKinstry,
       
       Deepika Bablani,
       
       Rathinakumar Appuswamy,
       
       Dharmendra S. Modha
       
     </h5>
     
     <center class="p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
         <button class="btn btn-outline-secondary">
           Abstract
         </button>
       </a>
       

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/dfe1a1f3149bbae490a4bc4e9b137dfc585c06c4.pdf">
         <button class="btn btn-outline-secondary">
           Paper
         </button>
       </a>
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=rkgO66VKDS">
         <button class="btn btn-outline-secondary">
           OpenReview
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Zoom
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Code
         </button>
       </a>
       
       <a href="" target="_blank"  class="card-link">
         <button class="btn btn-outline-secondary">
           Slides
         </button>
       </a>
     </center>
     
   </div>
 </div>

 <div id="details" class="card m-3 collapse" style=" box-shadow: 2px 2px 14px 0px rgba(204, 204, 204, 1);">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Deep networks run with low precision operations at inference time offer power and space advantages over high precision alternatives, but need to overcome the challenge of maintaining high accuracy as precision decreases. Here, we present a method for training such networks, Learned Step Size Quantization, that achieves the highest accuracy to date on the ImageNet dataset when using models, from a variety of architectures, with weights and activations quantized to 2-, 3- or 4-bits of precision, and that can train 3-bit models that reach full precision baseline accuracy. Our approach builds upon existing methods for learning weights in quantized networks by improving how the quantizer itself is configured. Specifically, we introduce a novel means to estimate and scale the task loss gradient at each weight and activation layer&#39;s quantizer step size, such that it can be learned in conjunction with other network parameters. This approach works using different levels of precision as needed for a given system and requires only a simple modification of existing training code.
       </div>
       
     </p>
     
     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="keyword_deep learning.html" class="text-secondary text-decoration-none">deep learning</a>,
       
       <a href="keyword_low precision.html" class="text-secondary text-decoration-none">low precision</a>,
       
       <a href="keyword_classification.html" class="text-secondary text-decoration-none">classification</a>,
       
       <a href="keyword_quantization.html" class="text-secondary text-decoration-none">quantization</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



<div class="container ">
  <div class="row m-2">
    <div class="col-7">
      <div id="presentation-embed-38915748" class="slp"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        allowHiddenControlsWhenPaused: true,
        zoomRatio: 0.4,
        hideTitle: true
        });
      </script>
    </div>
    
    <div class="col-5 p-1 my-auto">        
        <div id="gitter" class="gitter container " >
          <center>
            <div class="border">
              <center> <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_rkgO66VKDS?layout=embedded" width="100%" height="680px"></iframe> </center>
            </div>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">
  

      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_H1lBj2VFPS.html" class="text-dark"><h5 class="card-title">Linear Symmetric Quantization of Neural Networks for Low-precision Integer Hardware</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/H1lBj2VFPS.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> We introduce an efficient quantization process that allows for performance acceleration on specialized integer-only neural network accelerator.</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_BkgXT24tDS.html" class="text-dark"><h5 class="card-title">Additive Powers-of-Two Quantization: An Efficient Non-uniform Discretization for Neural Networks</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/BkgXT24tDS.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> We propose Additive Powers-of-Two~(APoT) quantization, an efficient non-uniform quantization scheme for the bell-shaped and long-tailed distribution of weights and activations in neural networks. By constraining all quantization levels as the sum of ...</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_Hyx0slrFvH.html" class="text-dark"><h5 class="card-title">Mixed Precision DNNs: All you need is a good parametrization</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/Hyx0slrFvH.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Efficient deep neural network (DNN) inference on mobile or embedded devices typically involves quantization of the network parameters and activations. In particular, mixed precision networks achieve better performance than networks with homogeneous b...</p>
            
          </div>      
        </div>
      </div>
      
      <div class="col-3">
        <div class="card" >
          <div class="card-header text-center">
            <a href="poster_rJehVyrKwH.html" class="text-dark"><h5 class="card-title">And the Bit Goes Down: Revisiting the Quantization of Neural Networks</h5></a>
            <center><img src="https://iclr.github.io/iclr-images/rJehVyrKwH.png" width="75%"  style="margin-bottom: 20px; margin-top: 20px; border-radius: 0; border: 4px solid #eee;box-shadow: 2px 2px 8px 0 #ccc;"/></center>

            <p class="card-text"> Using a structured quantization technique aiming at better in-domain reconstruction to compress convolutional neural networks</p>
            
          </div>      
        </div>
      </div>
      
  </DIV>
</DIV>

</body>