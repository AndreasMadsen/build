<!doctype html>
<html lang="en">
  
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport"
          content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="static/css/main.css">

    <script src="https://d3js.org/d3.v5.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/handlebars.js/4.7.3/handlebars.min.js"
            integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU="
            crossorigin="anonymous"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js"
            integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo="
            crossorigin="anonymous"></script>

    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


    <script src="static/js/typeahead.bundle.js"></script>

    <link rel="stylesheet" href="static/css/typeahead.css">
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
          integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T"
          crossorigin="anonymous">

    <title> ICLR: Dream to Control: Learning Behaviors by Latent Imagination </title>
</head>


  <body >

<!-- NAV -->

<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Lato:400,900&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css?family=Exo" rel='stylesheet'>
<link href="https://fonts.googleapis.com/css?family=Cuprum" rel='stylesheet'>
<nav class="navbar sticky-top navbar-expand-lg navbar-light bg-light mr-auto " id="main-nav" >
  <div class="container">
    <a class="navbar-brand" href="index.html">
      <img class="logo" style='visibility: ' src="static/images/ICLR-logo.png"  width="180px" />

    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
      <ul class="navbar-nav ml-auto">
        
        <li class="nav-item ">
          <a class="nav-link"    href="index.html">Home</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="calendar.html">Schedule</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="workshops.html">Workshops</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="papers.html">Papers</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link" target="_blank"   href="https://iclr.6connex.com/event/VirtualEvent/">Sponsor Hall</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="socials.html">Socials</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="chat.html">Chat</a>
        </li>
        
        <li class="nav-item ">
          <a class="nav-link"    href="about.html">Help</a>
        </li>
        
      </ul>
    </div>
  </div>
</nav>


<div class="container">

 <!-- Title -->

 <div class="pp-card m-3" style="">
   <div class="card-header">
     <h2 class="card-title main-title text-center" style="">
       Dream to Control: Learning Behaviors by Latent Imagination
     </h2>

     <h3 class="card-subtitle mb-2 text-muted text-center">
       
       Danijar Hafner,
       
       Timothy Lillicrap,
       
       Jimmy Ba,
       
       Mohammad Norouzi
       
     </h3>

     <div class="text-center p-3">
       <a class="card-link" data-toggle="collapse" role="button" href="#details">
           Abstract
       </a>

       <a class="card-link"  target="_blank" href="http://www.openreview.net/pdf/44e065d7c90164bc171c03b35c18c7975f82bdcc.pdf">
           Paper
       </a>
       
       <a href="https://danijar.com/dreamer" target="_blank"  class="card-link">
           Code
       </a>
       
       
       <a class="card-link"  target="_blank"  href="http://www.openreview.net/forum?id=S1lOTC4tDS">
           Reviews
       </a>

       <!--  -->
       <!-- <a href="" target="_blank"  class="card-link"> -->
       <!--   Slides -->
       <!-- </a> -->
       <!--  -->

       <!-- </div> -->
     
     <!-- <div class="text-center "> -->
       <a href="" target="_blank"  class="card-link">
           Video
       </a>

       <a href="chat.html?room=channel/paper_channel_S1lOTC4tDS" target="_blank"  class="card-link">
           Chat
       </a>

       


     </div>
   </div>

   </div>

 <div id="details" class="pp-card m-3 collapse">
   <div class="card-body">
     <p class="card-text">
       <div id="abstractExample">
         <span class="font-weight-bold">Abstract:</span>
         Learned world models summarize an agent&#39;s experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.
       </div>

     </p>

     <p></p>
     <p class="card-text"><span class="font-weight-bold">Keywords:</span>
       
       <a href="papers.html?filter=keywords&search=world model" class="text-secondary text-decoration-none">world model</a>,
       
       <a href="papers.html?filter=keywords&search=latent dynamics" class="text-secondary text-decoration-none">latent dynamics</a>,
       
       <a href="papers.html?filter=keywords&search=imagination" class="text-secondary text-decoration-none">imagination</a>,
       
       <a href="papers.html?filter=keywords&search=planning by backprop" class="text-secondary text-decoration-none">planning by backprop</a>,
       
       <a href="papers.html?filter=keywords&search=policy optimization" class="text-secondary text-decoration-none">policy optimization</a>,
       
       <a href="papers.html?filter=keywords&search=planning" class="text-secondary text-decoration-none">planning</a>,
       
       <a href="papers.html?filter=keywords&search=reinforcement learning" class="text-secondary text-decoration-none">reinforcement learning</a>,
       
       <a href="papers.html?filter=keywords&search=control" class="text-secondary text-decoration-none">control</a>,
       
       <a href="papers.html?filter=keywords&search=representations" class="text-secondary text-decoration-none">representations</a>,
       
       <a href="papers.html?filter=keywords&search=latent variable model" class="text-secondary text-decoration-none">latent variable model</a>,
       
       <a href="papers.html?filter=keywords&search=visual control" class="text-secondary text-decoration-none">visual control</a>,
       
       <a href="papers.html?filter=keywords&search=value function" class="text-secondary text-decoration-none">value function</a>
       
     </p>
   </div>
 </div>

</div>

<!-- SlidesLive -->



 <div class="container" style="background-color:white; padding: 0px;">
  <div class="row m-2">
    <div class="col-md-7 col-xs-12 my-auto p-2" >
      <div id="presentation-embed-38915748" class="slp my-auto"></div>
      <script src='https://slideslive.com/embed_presentation.js'></script>
      <script>
        embed = new SlidesLiveEmbed('presentation-embed-38915748', {
        presentationId: '38915748',
        autoPlay: false, // change to true to autoplay the embedded presentation
        verticalEnabled: true,
        verticalWhenWidthLte: 2000,
        allowHiddenControlsWhenPaused: true,
        hideTitle: true
        });
      </script>
    </div>

    <div class="col-md-5 col-xs-12 p-2">
        <div id="gitter" class="slp">
          <center>
             <iframe frameborder="0" src="https://iclr.rocket.chat/channel/paper_channel_S1lOTC4tDS?layout=embedded" height="700px" width="100%" ></iframe>
          </center>
        </div>
      </div>
    </div>
  </div>
</div>

  <!-- Recs -->
  <p></p>


  <div  class="container" style="padding-bottom: 30px; padding-top:30px">
  <center>
    <h2> Similar Papers </h2>
</div>
<p></p>

<div  class="container" >
  <div class="row">

      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_HJgLZR4KvH.html" class="text-muted">
              <h5 class="card-title" align="center">Dynamics-Aware Unsupervised Skill Discovery</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Archit Sharma,
              
              Shixiang Gu,
              
              Sergey Levine,
              
              Vikash Kumar,
              
              Karol Hausman,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/HJgLZR4KvH.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose an unsupervised skill discovery which enables model-based planning for hierarchical reinforcement learning.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_SJg5J6NtDr.html" class="text-muted">
              <h5 class="card-title" align="center">Watch, Try, Learn: Meta-Learning from Demonstrations and Rewards</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Allan Zhou,
              
              Eric Jang,
              
              Daniel Kappler,
              
              Alex Herzog,
              
              Mohi Khansari,
              
              Paul Wohlhart,
              
              Yunfei Bai,
              
              Mrinal Kalakrishnan,
              
              Sergey Levine,
              
              Chelsea Finn,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/SJg5J6NtDr.png" width="80%"/></center>

            <!-- <p class="card-text"> Imitation learning allows agents to learn complex behaviors from demonstrations. However, learning a complex vision-based task may require an impractical number of demonstrations. Meta-imitation learning is a promising approach towards enabling agent...</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_H1ezFREtwH.html" class="text-muted">
              <h5 class="card-title" align="center">Composing Task-Agnostic Policies with Deep Reinforcement Learning</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Ahmed H. Qureshi,
              
              Jacob J. Johnson,
              
              Yuzhe Qin,
              
              Taylor Henderson,
              
              Byron Boots,
              
              Michael C. Yip,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/H1ezFREtwH.png" width="80%"/></center>

            <!-- <p class="card-text"> We propose a novel reinforcement learning-based skill transfer and composition method that takes the agent&#39;s primitive policies to solve unseen tasks.</p> -->

          </div>
        </div>
      </div>
      
      <div class="col-md-4 col-xs-6">
        <div class="pp-card" >
          <div class="pp-card-header" class="text-muted">
            <a href="poster_rylvYaNYDH.html" class="text-muted">
              <h5 class="card-title" align="center">Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents</h5></a>
            <h6 class="card-subtitle text-muted" align="center">
              
              Christian Rupprecht,
              
              Cyril Ibrahim,
              
              Christopher J. Pal,
              
            </h6>

            <center><img class="cards_img" src="https://iclr.github.io/iclr-images/rylvYaNYDH.png" width="80%"/></center>

            <!-- <p class="card-text"> We generate critical states of a trained RL algorithms to visualize potential weaknesses. </p> -->

          </div>
        </div>
      </div>
      
  </DIV>
</DIV>

</body>